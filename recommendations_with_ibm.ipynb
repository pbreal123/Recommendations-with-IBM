{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Recommendations with IBM\n", "This notebook contains the code for the IBM recommendation system project."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 1. Importing Libraries and Loading the Data\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.decomposition import TruncatedSVD\n", "from sklearn.metrics.pairwise import cosine_similarity\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "import matplotlib.pyplot as plt\n\n", "# Load datasets\n", "df_user_item = pd.read_csv('data/user-item-interactions.csv')\n", "df_articles = pd.read_csv('data/articles.csv')\n\n", "# View the first few rows of the datasets\n", "df_user_item.head(), df_articles.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Data Exploration and Preprocessing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Checking for missing values and data types\n", "print(df_user_item.info())\n", "print(df_articles.info())\n\n", "# Descriptive statistics of interactions and articles\n", "print(df_user_item.describe())\n", "print(df_articles.describe())\n\n", "# Dropping duplicates if any\n", "df_user_item.drop_duplicates(inplace=True)\n", "df_articles.drop_duplicates(inplace=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Rank-Based Recommendation System"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_top_articles(df, n=10):\n", "    # Rank articles based on the number of interactions\n", "    article_counts = df['article_id'].value_counts().head(n)\n", "    return article_counts.index.tolist()\n\n", "def get_top_article_names(df, n=10):\n", "    top_articles_ids = get_top_articles(df, n)\n", "    return df_articles[df_articles['article_id'].isin(top_articles_ids)]['title'].unique()\n\n", "# Top 10 articles by interactions\n", "print(get_top_article_names(df_user_item, n=10))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Collaborative Filtering Using Matrix Factorization (SVD)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create the user-item matrix\n", "user_item_matrix = df_user_item.pivot(index='user_id', columns='article_id', values='interaction').fillna(0)\n\n", "# Perform Singular Value Decomposition (SVD)\n", "svd = TruncatedSVD(n_components=50, random_state=42)\n", "latent_matrix = svd.fit_transform(user_item_matrix)\n\n", "# Compute similarity between articles\n", "similarity_matrix = cosine_similarity(latent_matrix)\n\n", "def find_similar_items(item_id, n=10):\n", "    item_index = user_item_matrix.columns.get_loc(item_id)\n", "    similar_items = similarity_matrix[item_index].argsort()[-n:]\n", "    return user_item_matrix.columns[similar_items]\n\n", "# Example: Find 10 articles similar to article 123\n", "print(find_similar_items(article_id=123, n=10))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Content-Based Filtering Using TF-IDF"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Extract article content features using TF-IDF\n", "tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n", "article_tfidf = tfidf.fit_transform(df_articles['content'])\n\n", "# Compute cosine similarity based on article content\n", "def find_similar_content(article_id, n=10):\n", "    article_index = df_articles.index[df_articles['article_id'] == article_id].tolist()[0]\n", "    cosine_similarities = cosine_similarity(article_tfidf[article_index], article_tfidf).flatten()\n", "    related_articles_indices = cosine_similarities.argsort()[-n:]\n", "    return df_articles.iloc[related_articles_indices]['title']\n\n", "# Example: Find 10 articles similar in content to article 123\n", "print(find_similar_content(article_id=123, n=10))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Hybrid Recommendation System"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def hybrid_recommendation(article_id, n=10, alpha=0.5):\n", "    similar_items = find_similar_items(article_id, n)\n", "    similar_content = find_similar_content(article_id, n)\n\n", "    hybrid_recommendations = pd.concat([similar_items, similar_content]).drop_duplicates()\n\n", "    # Weight collaborative vs content-based recommendations\n", "    return hybrid_recommendations.sample(frac=alpha, random_state=42).head(n)\n\n", "# Example: Hybrid recommendation for article 123\n", "print(hybrid_recommendation(article_id=123, n=10))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. Evaluation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import precision_score, recall_score, f1_score\n\n", "# Example: Evaluate recommendations using Precision, Recall, and F1-score\n", "y_true = [1, 0, 1, 1, 0]  # True labels\n", "y_pred = [1, 0, 1, 0, 1]  # Predicted recommendations\n\n", "# Evaluation metrics\n", "precision = precision_score(y_true, y_pred)\n", "recall = recall_score(y_true, y_pred)\n", "f1 = f1_score(y_true, y_pred)\n\n", "print(f\"Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}